{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import MmCorpus, Dictionary\n",
    "from gensim import similarities\n",
    "import numpy as np\n",
    "from tables import *\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_path = \"/mnt/disks/sdb/data/pub_full_tfidf.mm\"\n",
    "ids_path = \"/mnt/disks/sdb/data/abs_cits.txt\"\n",
    "path = \"/mnt/disks/sdc/data_journals/\"\n",
    "out_path = path + \"sim/\"\n",
    "dict_path = \"/mnt/disks/sdb/data/dct.p\"\n",
    "info_path = \"/mnt/disks/sdb/data/pub_exp_info.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = Dictionary.load(dict_path)\n",
    "num_features= len(dictionary)\n",
    "del dictionary\n",
    "mm_tfidf = MmCorpus(tfidf_path)\n",
    "with open(ids_path,'r') as f:\n",
    "    abs_cits = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(ids_path,'r') as f:\n",
    "    abs_cits = f.readlines()\n",
    "abs_cits = np.array([int(x.strip()) for x in abs_cits])\n",
    "abs_dict = {x:i for i,x in enumerate(abs_cits)}\n",
    "del abs_cits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(path+'dict_journals_year.p','rb') as f:\n",
    "    dict_journals_years = pickle.load(f)\n",
    "journals_years = list(dict_journals_years.keys())\n",
    "nb_journals_years = len(journals_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_sim(inqueue,id_out):\n",
    "    for journal_year in iter(inqueue.get,sentinel):\n",
    "        journal = journal_year[0]\n",
    "        list_arts = dict_journals_years[journal_year]\n",
    "        comps = []\n",
    "        for art in list_arts:\n",
    "            if art in abs_dict.keys():\n",
    "                comps.append(art)\n",
    "        del list_arts\n",
    "                      \n",
    "        nb_IDs = len(comps) \n",
    "        nb_batches = int(np.ceil(nb_IDs/batch_size))\n",
    "        if nb_batches == 1:\n",
    "            tfidf_b = [mm_tfidf[abs_dict[k]] for k in comps]\n",
    "            index = similarities.SparseMatrixSimilarity(tfidf_b,num_features=num_features)\n",
    "            sim = index[tfidf_b]\n",
    "            comp_map_b = {i:x for i,x in enumerate(comps)}\n",
    "            pairs_id = np.tril_indices(sim.shape[0],-1)\n",
    "            pairs_sim = []\n",
    "            for j in range(len(pairs_id[0])):\n",
    "                pairs_sim.append([comp_map_b[pairs_id[0][j]],comp_map_b[pairs_id[1][j]],sim[pairs_id[0][j],pairs_id[1][j]]])\n",
    "            handle_output([pairs_sim,journal,True,id_out])\n",
    "       \n",
    "        elif nb_batches > 1:\n",
    "            for i_b in range(nb_batches-1):\n",
    "                s_i = i_b*batch_size\n",
    "                if i_b == nb_batches-2:\n",
    "                    e_i = nb_IDs\n",
    "                else:\n",
    "                    e_i = (i_b+1)*batch_size\n",
    "                comps_i = comps[s_i:e_i]\n",
    "                tfidf_i = [mm_tfidf[abs_dict[k]] for k in comps_i]\n",
    "                index = similarities.SparseMatrixSimilarity(tfidf_i,num_features=num_features)\n",
    "                comp_map_i = {i:x for i,x in enumerate(comps_i)}\n",
    "                for j_b in range(i_b,nb_batches-1):\n",
    "                    s_j = j_b*batch_size\n",
    "                    if j_b == nb_batches-2:\n",
    "                        e_j = nb_IDs\n",
    "                    else:\n",
    "                        e_j = (j_b+1)*batch_size\n",
    "                    comps_j = comps[s_j:e_j]\n",
    "                    tfidf_j = [mm_tfidf[abs_dict[k]] for k in comps_j]\n",
    "                    sim = index[tfidf_j]\n",
    "                    comp_map_j = {i:x for i,x in enumerate(comps_j)}\n",
    "                    if i_b == j_b:\n",
    "                        pairs_id = np.tril_indices(sim.shape[0],-1)\n",
    "                        pairs_sim = []\n",
    "                        for j in range(len(pairs_id[0])):\n",
    "                            pairs_sim.append([comp_map_i[pairs_id[0][j]],comp_map_j[pairs_id[1][j]],sim[pairs_id[0][j],pairs_id[1][j]]])\n",
    "                    else:\n",
    "                        dim_mat = sim.shape\n",
    "                        pairs_sim = []\n",
    "                        for dim_i in range(dim_mat[0]):\n",
    "                            for dim_j in range(dim_mat[1]):\n",
    "                                pairs_sim.append([comp_map_i[dim_j],comp_map_j[dim_i],sim[dim_i,dim_j]])\n",
    "                    if i_b == nb_batches-2 and j_b == nb_batches-2:\n",
    "                        handle_output([pairs_sim,journal,True,id_out])\n",
    "                    else:\n",
    "                        handle_output([pairs_sim,journal,False,id_out])\n",
    "        else:\n",
    "            handle_output([[],None,True,id_out])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out to txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_output(args):\n",
    "    if len(args[0]) > 0:\n",
    "        cont = False\n",
    "        while True:\n",
    "            try:\n",
    "                fo = open('{}output_{}.txt'.format(out_path,args[3]),'a')\n",
    "                for line in args[0]: \n",
    "                    fo.write('{0},{1},{2:.4f}\\n'.format(line[0],line[1],line[2]))\n",
    "                fo.flush()\n",
    "                fo.close()\n",
    "                break\n",
    "            except IOError:\n",
    "                time.sleep(0.5)\n",
    "\n",
    "    if args[2]:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        elapsed_time_h = np.round(elapsed_time/3600,2)\n",
    "        while True:\n",
    "            try:\n",
    "#                 fp = open('{}../progress.txt'.format(out_path),'r')\n",
    "#                 counter = 1\n",
    "#                 for counter, l in enumerate(fp):\n",
    "#                     pass\n",
    "#                 fp.close()\n",
    "                \n",
    "                fp = open('{}../progress.txt'.format(out_path),'a')\n",
    "                #fp.write('Progress: {}/{} journals, Time since start: {}\\n'.format(counter+2,nb_journals_years,elapsed_time_h))\n",
    "                fp.write('Progress: {}/{} journals, Time since start: {}\\n'.format('',nb_journals_years,elapsed_time_h))    \n",
    "                fp.flush()\n",
    "                fp.close()\n",
    "                break\n",
    "            except IOError:\n",
    "                time.sleep(0.2)\n",
    "         \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'proc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-dd6112fe6bbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'proc' is not defined"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "start_time = time.time()\n",
    "fp = open('{}../progress.txt'.format(out_path),'w')\n",
    "fp.close()\n",
    "\n",
    "\n",
    "num_processes = mp.cpu_count()-1\n",
    "sentinel = None\n",
    "manager = mp.Manager()\n",
    "inqueue = mp.Queue()\n",
    "jobs = []\n",
    "\n",
    "\n",
    "for i in range(num_processes):\n",
    "    p = mp.Process(target=compute_sim, args=(inqueue,i,))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "idx_journals = np.arange(nb_journals_years)\n",
    "np.random.shuffle(idx_journals)\n",
    "for i in idx_journals:\n",
    "    inqueue.put(journals_years[i])\n",
    "for i in range(num_processes):\n",
    "    # Send the sentinal to tell Simulation to end\n",
    "    inqueue.put(sentinel)\n",
    "for p in jobs:\n",
    "    p.join()\n",
    "\n",
    "proc.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "start_time = time.time()\n",
    "fp = open('{}../progress.txt'.format(out_path),'w')\n",
    "fp.close()\n",
    "\n",
    "\n",
    "nb_outputs = 7\n",
    "num_processes = mp.cpu_count()-nb_outputs-1\n",
    "sentinel = None\n",
    "manager = mp.Manager()\n",
    "output = mp.Queue()\n",
    "inqueue = mp.Queue()\n",
    "jobs = []\n",
    "\n",
    "for id_out in range(nb_outputs):\n",
    "    proc = mp.Process(target=handle_output, args=(output,))\n",
    "    proc.start()\n",
    "\n",
    "for i in range(num_processes):\n",
    "    p = mp.Process(target=compute_sim, args=(inqueue, output))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "idx_journals = np.arange(nb_journals)\n",
    "np.random.shuffle(idx_journals)\n",
    "for i in idx_journals:\n",
    "    inqueue.put(journals[i])\n",
    "for i in range(num_processes):\n",
    "    # Send the sentinal to tell Simulation to end\n",
    "    inqueue.put(sentinel)\n",
    "for p in jobs:\n",
    "    p.join()\n",
    "output.put(None)\n",
    "proc.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queue_cont = []\n",
    "while True:\n",
    "    args = output.get()\n",
    "    if args:\n",
    "        queue_cont.append(args)\n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(queue_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_i = [tfidf[0]] \n",
    "index = similarities.SparseMatrixSimilarity(tfidf_i,num_features=num_features)\n",
    "tfidf_j = [tfidf[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim = index[tfidf_j]\n",
    "\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(range(nb_batches-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(tfidf_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.pcolor(temp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "for i in output:\n",
    "    total += len(i[0])\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(np.tril_indices(nb_IDs,-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_IDs*(nb_IDs-1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = list(abs_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i_b in range(nb_batches):#range(nb_batch):\n",
    "    for j_b in range(i_b,nb_batches):\n",
    "        temp.append([i_b,j_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
