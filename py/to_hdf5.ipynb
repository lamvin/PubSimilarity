{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from tables import *\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PubExp(IsDescription):\n",
    "    Id_Art = UInt32Col()\n",
    "    Ordre = UInt8Col()\n",
    "    Abstract = StringCol(itemsize=4000, dflt=\" \", pos=0)  # character String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/mnt/disks/sec/data/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 287.8104214668274 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "with open(data_path+'pub_full.txt') as f:\n",
    "    for nb_l, l in enumerate(f):\n",
    "        pass\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "h5file = open_file(data_path + 'pub_full.h5', mode=\"w\", title=\"pub_sample\")\n",
    "group = h5file.create_group(\"/\", 'pub_exp')\n",
    "table = h5file.create_table(group, 'sample', PubExp)\n",
    "abstract = table.row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from nltk import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = x.lower()\n",
    "    x = re.sub(r'\\d+', '', x)\n",
    "    x = x.translate(str.maketrans('','',string.punctuation)).strip()\n",
    "    tokens = x.split(' ')\n",
    "    result = [stemmer.stem(i) for i in tokens if not i in sw]\n",
    "    return ' '.join(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "block_len = 1000\n",
    "prev_ID = None\n",
    "block = []\n",
    "first_block = True\n",
    "with open(data_path+'pub_full.txt', newline='') as f:\n",
    "    reader = csv.reader(f,delimiter='\\t')\n",
    "    next(reader)\n",
    "    text = ''\n",
    "    for i in tqdm(range(nb_l)):\n",
    "        line = next(reader)\n",
    "        abstract['Id_Art'] = int(line[0])\n",
    "        abstract['Ordre'] = int(line[1])\n",
    "        cur_text = preprocess(line[2])\n",
    "        abstract['Abstract'] = cur_text\n",
    "        abstract.append()\n",
    "        ID = line[0]\n",
    "        if ID == prev_ID:\n",
    "            text = text + ' ' + cur_text\n",
    "        else:\n",
    "            block.append(text)\n",
    "            text = cur_text\n",
    "        prev_ID = ID\n",
    "        if (i+1)%block_len == 0:\n",
    "            if first_block:\n",
    "                dct = Dictionary([[line for line in doc.split()] for doc in block])\n",
    "                first_block = False\n",
    "            else:\n",
    "                dct.add_documents([[line for line in doc.split()] for doc in block])\n",
    "            block = []\n",
    "dct.add_documents([[line for line in doc.split()] for doc in block])\n",
    "table.flush()\n",
    "end_time = time.time()\n",
    "with open(data_path+'dct.p','wb') as f:\n",
    "    dct.save(f)\n",
    "print(\"--- %s seconds ---\" % ( - start_time))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
