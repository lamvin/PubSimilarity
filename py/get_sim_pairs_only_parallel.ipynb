{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import MmCorpus, Dictionary\n",
    "from gensim import similarities\n",
    "import numpy as np\n",
    "from tables import *\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimPairs(IsDescription):\n",
    "    Citant = UInt32Col()\n",
    "    Cite = UInt32Col()\n",
    "    Sim = Float16Col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_path = \"/mnt/disks/sdb/data/pub_full_tfidf.mm\"\n",
    "ids_path = \"/mnt/disks/sdb/data/abs_cits.txt\"\n",
    "cits_path = \"/mnt/disks/sdb/data/DictCits.h5\"\n",
    "out_path = \"/mnt/disks/sdd/data/\"\n",
    "dict_path = \"/mnt/disks/sdb/data/dct.p\"\n",
    "info_path = \"/mnt/disks/sdb/data/pub_exp_info.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5file_cits = open_file(cits_path, mode=\"r\", title=\"DictCits\")\n",
    "table_cits = h5file_cits.root.pub_exp.DictCits\n",
    "nb_l_cits = len(table_cits)\n",
    "nb_citants_incl = nb_l_cits\n",
    "h5file_cits.close()\n",
    "del table_cits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = Dictionary.load(dict_path)\n",
    "num_features= len(dictionary)\n",
    "del dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mm_tfidf = MmCorpus(tfidf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(ids_path,'r') as f:\n",
    "    abs_cits = f.readlines()\n",
    "abs_cits = np.array([int(x.strip()) for x in abs_cits])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abs_dict = {x:i for i,x in enumerate(abs_cits)}\n",
    "del abs_cits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "years = np.arange(1898,2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5file_sim = open_file(out_path + 'similarity_refs_only.h5', mode=\"w\", title=\"similarity\")\n",
    "group = h5file_sim.create_group(\"/\", \"citations\")\n",
    "h5file_sim.create_table(group, \"sim\", SimPairs)\n",
    "h5file_sim.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arr_from_bytes(arr,add):\n",
    "    return np.fromstring(arr + bytes(add),dtype=np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5file_cits = open_file(cits_path, mode=\"r\", title=\"DictCits\")\n",
    "table_cits = h5file_cits.root.pub_exp.DictCits\n",
    "i=3\n",
    "line_cits = table_cits[i]\n",
    "citant = line_cits['citant']\n",
    "loaded = False\n",
    "add = 0\n",
    "while not loaded:\n",
    "    try:\n",
    "        cites = arr_from_bytes(line_cits['cites'],add)\n",
    "        loaded = True\n",
    "    except ValueError:\n",
    "        add += 1\n",
    "    if add > 5:\n",
    "        break\n",
    "if loaded:\n",
    "    if citant in abs_dict.keys():\n",
    "        tfidf_base = mm_tfidf[abs_dict[citant]]\n",
    "        comps = []\n",
    "        for cite in cites:\n",
    "            if cite in abs_dict.keys():\n",
    "                comps.append(cite)\n",
    "        if comps:\n",
    "            tfidf_comps = []\n",
    "            for Art_ID in comps:\n",
    "                tfidf_comps.append(mm_tfidf[abs_dict[Art_ID]])\n",
    "            index = similarities.SparseMatrixSimilarity([tfidf_base],num_features=num_features) #check if num ft has impact on time\n",
    "            sim = index[tfidf_comps]\n",
    "            pairs_sim = []\n",
    "            for j in range(len(comps)):\n",
    "                pairs_sim.append([citant,comps[j],sim[j][0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_sim(inqueue, output):\n",
    "    h5file_cits = open_file(cits_path, mode=\"r\", title=\"DictCits\")\n",
    "    table_cits = h5file_cits.root.pub_exp.DictCits\n",
    "    for i in iter(inqueue.get,sentinel):\n",
    "        line_cits = table_cits[i]\n",
    "        citant = line_cits['citant']\n",
    "        loaded = False\n",
    "        add = 0\n",
    "        while not loaded:\n",
    "            try:\n",
    "                cites = arr_from_bytes(line_cits['cites'],add)\n",
    "                loaded = True\n",
    "            except ValueError:\n",
    "                add += 1\n",
    "            if add > 5:\n",
    "                break\n",
    "        if loaded:\n",
    "            if citant in abs_dict.keys():\n",
    "                tfidf_base = mm_tfidf[abs_dict[citant]]\n",
    "                comps = []\n",
    "                for cite in cites:\n",
    "                    if cite in abs_dict.keys():\n",
    "                        comps.append(cite)\n",
    "                if comps:\n",
    "                    tfidf_comps = []\n",
    "                    for Art_ID in comps:\n",
    "                        tfidf_comps.append(mm_tfidf[abs_dict[Art_ID]])\n",
    "                    index = similarities.SparseMatrixSimilarity([tfidf_base],num_features=num_features) #check if num ft has impact on time\n",
    "                    sim = index[tfidf_comps]\n",
    "                    pairs_sim = []\n",
    "                    for j in range(len(comps)):\n",
    "                        pairs_sim.append([citant,comps[j],sim[j][0]])\n",
    "                    output.put(pairs_sim)\n",
    "                else:\n",
    "                    output.put(1)\n",
    "            else:\n",
    "                output.put(1)\n",
    "    h5file_cits.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_output(output):\n",
    "    start_time = time.time()\n",
    "    counter = 0\n",
    "    f = open(out_path+'progress.txt','w')\n",
    "    h5file_sim = open_file(out_path + 'similarity_refs_only.h5', mode=\"a\", title=\"similarity\")\n",
    "    table_sim = h5file_sim.root.citations.sim\n",
    "    row = table_sim.row\n",
    "    while True:\n",
    "        args = output.get()\n",
    "        if args:\n",
    "            if not isinstance(args,int):\n",
    "                for line in args: \n",
    "                    row['Citant'] = line[0]\n",
    "                    row['Cite'] = line[1]\n",
    "                    row['Sim'] = line[2]\n",
    "                    row.append()\n",
    "                    table_sim.flush()\n",
    "            counter += 1\n",
    "            if counter % 1000 == 0 :\n",
    "                elapsed_time = time.time() - start_time\n",
    "                elapsed_time_h = np.round(elapsed_time/3600,2)\n",
    "                time_per_art = elapsed_time/counter\n",
    "                time_left_h = np.round(time_per_art*(nb_citants_incl-counter)/3600,2)\n",
    "                perc = np.round(counter/nb_citants_incl*100,3)\n",
    "                f.write('Progress: {} manuscripts, {}%, Time since start: {}, Time left: {}\\n'.format(counter,perc,elapsed_time_h,time_left_h))    \n",
    "                f.flush()\n",
    "        else:\n",
    "            break\n",
    "    f.close()\n",
    "    h5file_sim.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processes = mp.cpu_count()-2\n",
    "sentinel = None\n",
    "manager = mp.Manager()\n",
    "output = mp.Queue()\n",
    "inqueue = mp.Queue()\n",
    "jobs = []\n",
    "proc = mp.Process(target=handle_output, args=(output, ))\n",
    "proc.start()\n",
    "\n",
    "for i in range(num_processes):\n",
    "    p = mp.Process(target=compute_sim, args=(inqueue, output))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "idx_citant = np.arange(nb_l_cits)\n",
    "np.random.shuffle(idx_citant)\n",
    "for i in idx_citant:\n",
    "    inqueue.put(i)\n",
    "for i in range(num_processes):\n",
    "    # Send the sentinal to tell Simulation to end\n",
    "    inqueue.put(sentinel)\n",
    "for p in jobs:\n",
    "    p.join()\n",
    "output.put(None)\n",
    "proc.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
