{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import MmCorpus, Dictionary\n",
    "from gensim import similarities\n",
    "import numpy as np\n",
    "from tables import *\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import csv\n",
    "from tqdm import tqdm_notebook as tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimPairs(IsDescription):\n",
    "    Citant = UInt32Col()\n",
    "    Cite = UInt32Col()\n",
    "    Sim = Float16Col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_path = \"/mnt/disks/sdb/data/pub_full_tfidf.mm\"\n",
    "ids_path = \"/mnt/disks/sdb/data/abs_cits.txt\"\n",
    "cits_path = \"/mnt/disks/sdb/data/DictCits.h5\"\n",
    "out_path = \"/mnt/disks/sdc/data/\"\n",
    "dict_path = \"/mnt/disks/sdb/data/dct.p\"\n",
    "info_path = \"/mnt/disks/sdb/data/pub_exp_info.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5file_cits = open_file(cits_path, mode=\"r\", title=\"DictCits\")\n",
    "table_cits = h5file_cits.root.pub_exp.DictCits\n",
    "nb_l_cits = len(table_cits)\n",
    "nb_citants_incl = nb_l_cits\n",
    "h5file_cits.close()\n",
    "del table_cits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = Dictionary.load(dict_path)\n",
    "num_features= len(dictionary)\n",
    "del dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mm_tfidf = MmCorpus(tfidf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(ids_path,'r') as f:\n",
    "    abs_cits = f.readlines()\n",
    "abs_cits = np.array([int(x.strip()) for x in abs_cits])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abs_dict = {x:i for i,x in enumerate(abs_cits)}\n",
    "del abs_cits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "years = np.arange(1898,2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file_sim = open_file(out_path + 'similarity_refs_only.h5', mode=\"w\", title=\"similarity\")\n",
    "group = h5file_sim.create_group(\"/\", \"citations\")\n",
    "h5file_sim.create_table(group, \"sim\", SimPairs)\n",
    "h5file_sim.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arr_from_bytes(arr,add):\n",
    "    return np.fromstring(arr + bytes(add),dtype=np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_citant = np.arange(nb_l_cits)\n",
    "np.random.shuffle(idx_citant)\n",
    "h5file_cits = open_file(cits_path, mode=\"r\", title=\"DictCits\")\n",
    "table_cits = h5file_cits.root.pub_exp.DictCits\n",
    "f = open(out_path+'progress.txt','w')\n",
    "h5file_sim = open_file(out_path + 'similarity_refs_only.h5', mode=\"a\", title=\"similarity\")\n",
    "table_sim = h5file_sim.root.citations.sim\n",
    "row = table_sim.row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31708"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/User1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e33a7feab646f7b0969d36a771ad52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-19dc5c16ff71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mtfidf_comps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mArt_ID\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mtfidf_comps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm_tfidf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mabs_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mArt_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseMatrixSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtfidf_base\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#check if num ft has impact on time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtfidf_comps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/corpora/indexedcorpus.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, docno)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSlicedCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger_types\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocbyoffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdocno\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;31m# TODO: no `docbyoffset` method, should be defined in this class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "start_time = time.time()\n",
    "for i in tqdm(idx_citant):\n",
    "    line_cits = table_cits[i]\n",
    "    citant = line_cits['citant']\n",
    "    loaded = False\n",
    "    add = 0\n",
    "    while not loaded:\n",
    "        try:\n",
    "            cites = arr_from_bytes(line_cits['cites'],add)\n",
    "            loaded = True\n",
    "        except ValueError:\n",
    "            add += 1\n",
    "        if add > 5:\n",
    "            break\n",
    "    if loaded:\n",
    "        if citant in abs_dict.keys():\n",
    "            tfidf_base = mm_tfidf[abs_dict[citant]]\n",
    "            comps = []\n",
    "            for cite in cites:\n",
    "                if cite in abs_dict.keys():\n",
    "                    comps.append(cite)\n",
    "            tfidf_comps = []\n",
    "            for Art_ID in comps:\n",
    "                tfidf_comps.append(mm_tfidf[abs_dict[Art_ID]])\n",
    "            index = similarities.SparseMatrixSimilarity([tfidf_base],num_features=num_features) #check if num ft has impact on time\n",
    "            sim = index[tfidf_comps]\n",
    "            pairs_sim = []\n",
    "            for j in range(len(comps)):\n",
    "                pairs_sim.append([citant,comps[j],sim[j][0]])\n",
    "            for line in pairs_sim: \n",
    "                row['Citant'] = line[0]\n",
    "                row['Cite'] = line[1]\n",
    "                row['Sim'] = line[2]\n",
    "                row.append()\n",
    "            counter += 1\n",
    "            table_sim.flush()\n",
    "            if counter % 100 == 0 :\n",
    "                elapsed_time = time.time() - start_time\n",
    "                elapsed_time_h = np.round(elapsed_time/3600,2)\n",
    "                time_per_art = elapsed_time/counter\n",
    "                time_left_h = np.round(time_per_art*(nb_citants_incl-counter)/3600,2)\n",
    "                perc = np.round(counter/nb_citants_incl*100,3)\n",
    "                f.write('Progress: {} manuscripts, {}%, Time since start: {}, Time left: {}\\n'.format(counter,perc,elapsed_time_h,time_left_h))    \n",
    "                f.flush()\n",
    "                \n",
    "h5file_cits.close()    \n",
    "f.close()\n",
    "h5file_sim.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_sim(inqueue, output):\n",
    "    h5file_cits = open_file(cits_path, mode=\"r\", title=\"DictCits\")\n",
    "    table_cits = h5file_cits.root.pub_exp.DictCits\n",
    "    for i in iter(inqueue.get,sentinel):\n",
    "        line_cits = table_cits[i]\n",
    "        citant = line_cits['citant']\n",
    "        loaded = False\n",
    "        add = 0\n",
    "        while not loaded:\n",
    "            try:\n",
    "                cites = arr_from_bytes(line_cits['cites'],add)\n",
    "                loaded = True\n",
    "            except ValueError:\n",
    "                add += 1\n",
    "            if add > 5:\n",
    "                break\n",
    "        if loaded:\n",
    "            if citant in abs_dict.keys():\n",
    "                tfidf_base = mm_tfidf[abs_dict[citant]]\n",
    "                comps = []\n",
    "                for cite in cites:\n",
    "                    if cite in abs_dict.keys():\n",
    "                        comps.append(cite)\n",
    "                tfidf_comps = []\n",
    "                for Art_ID in comps:\n",
    "                    tfidf_comps.append(mm_tfidf[abs_dict[Art_ID]])\n",
    "                index = similarities.SparseMatrixSimilarity([tfidf_base],num_features=num_features) #check if num ft has impact on time\n",
    "                sim = index[tfidf_comps]\n",
    "                pairs_sim = []\n",
    "                for j in range(len(comps)):\n",
    "                    pairs_sim.append([citant,comps[j],sim[j][0]])\n",
    "                output.put(pairs_sim)\n",
    "h5file_cits.close()    \n",
    "f.close()\n",
    "h5file_sim.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_output(output):\n",
    "    start_time = time.time()\n",
    "    counter = 0\n",
    "    f = open(out_path+'progress.txt','w')\n",
    "    h5file_sim = open_file(out_path + 'similarity_refs_only.h5', mode=\"a\", title=\"similarity\")\n",
    "    table_sim = h5file_sim.root.citations.sim\n",
    "    sim = table_sim.row\n",
    "    while True:\n",
    "        args = output.get()\n",
    "        if args:\n",
    "            for line in args: \n",
    "                sim['Citant'] = line[0]\n",
    "                sim['Cite'] = line[1]\n",
    "                sim['Sim'] = line[2]\n",
    "                sim.append()\n",
    "            counter += 1\n",
    "            table_sim.flush()\n",
    "            if counter % 1000 == 0 :\n",
    "                elapsed_time = time.time() - start_time\n",
    "                elapsed_time_h = np.round(elapsed_time/3600,2)\n",
    "                time_per_art = elapsed_time/counter\n",
    "                time_left_h = np.round(time_per_art*(nb_citants_incl-counter)/3600,2)\n",
    "                perc = np.round(counter/nb_citants_incl*100,3)\n",
    "                f.write('Progress: {} manuscripts, {}%, Time since start: {}, Time left: {}\\n'.format(counter,perc,elapsed_time_h,time_left_h))    \n",
    "                f.flush()\n",
    "        else:\n",
    "            break\n",
    "    f.close()\n",
    "    h5file_sim.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-158e037e3def>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0minqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_processes = mp.cpu_count()-10\n",
    "sentinel = None\n",
    "manager = mp.Manager()\n",
    "output = mp.Queue()\n",
    "inqueue = mp.Queue()\n",
    "jobs = []\n",
    "proc = mp.Process(target=handle_output, args=(output, ))\n",
    "proc.start()\n",
    "\n",
    "for i in range(num_processes):\n",
    "    p = mp.Process(target=compute_sim, args=(inqueue, output))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "idx_citant = np.arange(nb_l_cits)\n",
    "np.random.shuffle(idx_citant)\n",
    "for i in idx_citant:\n",
    "    inqueue.put(i)\n",
    "for i in range(num_processes):\n",
    "    # Send the sentinal to tell Simulation to end\n",
    "    inqueue.put(sentinel)\n",
    "for p in jobs:\n",
    "    p.join()\n",
    "output.put(None)\n",
    "proc.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5file_sim = open_file(out_path + 'similarity_refs_only.h5', mode=\"a\", title=\"similarity\")\n",
    "table_sim = h5file_sim.root.citations.sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11060947, 9549685,  0.15246582)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_sim[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
